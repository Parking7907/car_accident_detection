generals:
  warn: False                          # show warnings
  save_folder: /home/jinyoung/share/car_accident_dataset/experi/                 # saving directory
  savepsds: True                       # save psds data
  test_on_public_eval: False           # change test dataset to DESED Reak public_eval (default dataset is DESED Real Validation)
  ensemble_avg: False                  # perform ensemble average on the models saved in ensemble_dir
  ensemble_dir: /home/jinyoung/share/car_accident_dataset/experi/ensemble        # directory of models gathered for ensemble average
  batch_size: [12,12,24]
  batch_size_val: 24
  num_workers: 6


training:
  test_only: False                     # perform test without training, for the model saved in save_folder
  debug: False                         # debugging mode runs train/validation only 1 epoch, and automatically apply True for div_dataset
  div_dataset: False                   # divide datasets by div_ratio. for debugging purpose, to make train/valid/test through dataset faster
  div_ratio: 25
  seed: 42
  weak_split: 0.9                      # split the weak dataset so that "weak_split" of dataset is used to train and rest is used to validate
  n_epochs: 100                      #200 number of epochs to run
  n_epochs_warmup: 40                  #50 number of epochs used for exponential warmup
  val_thresholds: [0.5]                # thresholds used to compute f1 intersection in validation.
  n_test_thresholds: 50                # number of thresholds used to compute psds in test
  ema_factor: 0.999                    # ema factor for teacher model used in mean teacher model
  w_weak: 0                          #0.5 weight for weak classification cost
  w_cons_max: 2                        # max weight used for consistency loss
  w_weak_cons: 1                       # max weight for weak classification cost
  multigpu: False                      # use multi-gpu to train
  decode_weak_valid: 0                 # weak prediction masking on strong prediction,
  decode_weak_test: 1                  # 0: no weak prediction used, 1: weak prediction masking, 2: weak SED
  trainweak_only: False                # train the model without strong dataset
  trainweak_withstrong: False          # get weak classification from weak prediction of strong dataset
  afl_loss:                            # antisymmetrical focal loss. None if you wanna use BCE loss. if you want AFL, try [gamma, zeta]
  median_window: 7                     # length of median filter used to smooth prediction in inference

  #data augmentations
  mixup_rate: 0.5                      # rate at which mixup is applied on the training data
  mixup_type: soft                     # Soft mixup gives the ratio of the mix to the labels, hard mixup gives a 1 to every label present.
  time_mask_ratios: [ 5, 20 ]          # ratio of time masking application wrpt total time length. 1/20~1/5 of time frame will be masked
  transform:                           # hyperparameters for data augmentations that do not alter the label information.
    n_transform: 2                     # 0: no augmentation below is applied. 1: same augmentation below is applied on student/teacher model input. 2: different augmentations below is applied on student/teacher model input.
    choice: [ 1, 0, 0 ]                # apply the chosen data augmentations: [ FilterAugment, freq_mask, add_noise ]
    filter_db_range: [ -7.5, 6 ]       # db range of FilterAugment to be applied on each band
    filter_bands: [ 2, 5 ]             # range of frequency band number in FilterAugment
    freq_mask_ratio: 32                # maximum ratio of freuqnecy masking range. max 1/32 of total frequnecy number will be masked
    noise_snrs: [ 35, 40 ]             # snr of original signal wrpt the noise added.

feature:
  n_mels: 128
  frame_length: 2048
  hop_length: 256
  n_window: 2048
  sample_rate: 16000
  f_min: 0
  f_max: 8000
  audio_max_len: 10
  sr: 16000
  net_subsample: 4

CRNN:
  n_class: 4
  n_RNN_cell: 256
  n_RNN_layer: 2
  rec_dropout: 0
  attention: True

  n_input_ch: 1
  activation: cg
  conv_dropout: 0.5
  kernel: [ 3, 3, 3, 3, 3, 3, 3 ]
  pad: [ 1, 1, 1, 1, 1, 1, 1 ]
  stride: [ 1, 1, 1, 1, 1, 1, 1 ]
  n_filt: [ 32, 64, 128, 256, 256, 256, 256 ]
  pooling: [ [ 2, 2 ], [ 2, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ] ]

  #synth_folder: "/home/jinyoung/share/car_accident_dataset/Train"
  #synth_tsv:  "/home/jinyoung/share/car_accident_dataset/tsv/Train.tsv"
  #synth_val_folder: "/home/jinyoung/share/car_accident_dataset/Validation"
  #synth_val_tsv: "/home/jinyoung/share/car_accident_dataset/tsv/Validation.tsv"
  #synth_val_dur: "/home/jinyoung/share/car_accident_dataset/tsv/Validation_duration.tsv"
  #test_folder: "/home/jinyoung/share/car_accident_dataset/Test"
  #test_tsv: "/home/jinyoung/share/car_accident_dataset/tsv/Test.tsv"
  #test_dur: "/home/jinyoung/share/car_accident_dataset/tsv/Test_duration.tsv"
  #eval_folder: "/home/jinyoung/share/car_accident_dataset/Test"
  #eval_folder_44k: "/home/jinyoung/share/car_accident_dataset/Test"



dataset:                               # change with your paths if different.
  # NOTE: if you have data in 44kHz only then synth_folder will be the path where
  # resampled data will be placed.
  test_folder: "/home/jinyoung/share/car_accident_dataset/Test"
  test_tsv: "/home/jinyoung/share/car_accident_dataset/tsv/Test.tsv"
  test_dur: "/home/jinyoung/share/car_accident_dataset/tsv/Test_duration.tsv"
  
synth_dataset:                         # change with your paths if different.
  synth_train_folder: "/home/jinyoung/share/car_accident_dataset/Train"
  synth_train_tsv: "/home/jinyoung/share/car_accident_dataset/tsv/Train.tsv"
  synth_train_dur: "/home/jinyoung/share/car_accident_dataset/tsv/Train_duration.tsv"
  synth_val_folder: "/home/jinyoung/share/car_accident_dataset/Validation"
  synth_val_tsv: "/home/jinyoung/share/car_accident_dataset/tsv/Validation.tsv"
  synth_val_dur: "/home/jinyoung/share/car_accident_dataset/tsv/Validation_duration.tsv"
scaler:
  statistic: instance                  # instance or dataset-wide statistic
  normtype: minmax                     # minmax or standard or mean normalization
  dims: [ 0, 2 ]                       # dimensions over which normalization is applied
  savepath: ./scaler.ckpt              # path to scaler checkpoint
opt:
  lr: 0.001